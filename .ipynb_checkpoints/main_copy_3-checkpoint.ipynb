{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import data as dt\n",
    "import model as md\n",
    "import copy\n",
    "from pytorch_ssim import ssim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU: 3\n",
      "8\n",
      "(6, 1)\n",
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "# print gpu\n",
    "torch.cuda.set_device(3)\n",
    "currentDevice = torch.cuda.current_device()\n",
    "print(\"Current GPU: \" + str(currentDevice))\n",
    "print(str(torch.cuda.device_count()))\n",
    "print(str(torch.cuda.get_device_capability(currentDevice)))\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = 1\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:3')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate csv file, run only for the first time\n",
    "# dt.generate_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilePath = dt.get_csv_path()\n",
    "transformed_dataset = dt.HE_SHG_Dataset(csv_file=csvFilePath,\n",
    "                                               transform=dt.Compose([                                              \n",
    "                                               dt.Rescale(96),\n",
    "                                               dt.ToTensor(),\n",
    "                                               dt.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])                                           \n",
    "                                           ]))\n",
    "# TODO: change the normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize 32->16\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=32,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: insert back mean and variance to plot the image appropriately\n",
    "dt.show_patch(dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    }
   ],
   "source": [
    "print('===> Building model')\n",
    "model = md.Net().to(device)\n",
    "criterionMSE = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(dataloader):\n",
    "        input, target = batch['input'].to(device), batch['output'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        targetf = target.float()\n",
    "        targetf = targetf[:, None]\n",
    "        \n",
    "        lossMSE = criterionMSE(output, targetf)      \n",
    "        lossSSIM = -(ssim(output, targetf)-1)\n",
    "        \n",
    "        p = 0.25\n",
    "        loss = p*lossMSE + (1-p)*lossSSIM\n",
    "        combineLoss = p*lossMSE.item() + (1-p)*lossSSIM.item()\n",
    "        \n",
    "        epoch_loss = epoch_loss + combineLoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if iteration%50 == 0:\n",
    "            print(\"lossMSE: \" + str(lossMSE.item()) +\n",
    "                  \" \" + \"lossSSIM: \" + str(lossSSIM.item()))\n",
    "            print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(dataloader), loss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(dataloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     avg_psnr = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in testing_data_loader:\n",
    "#             input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "#             prediction = model(input)\n",
    "#             mse = criterion(prediction, target)\n",
    "#             psnr = 10 * log10(1 / mse.item())\n",
    "#             avg_psnr += psnr\n",
    "#     print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkpoint(epoch):\n",
    "#     model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
    "#     torch.save(model, model_out_path)\n",
    "#     print(\"Checkpoint saved to {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossMSE: 2.2096481323242188 lossSSIM: 1.0789344310760498\n",
      "===> Epoch[1](0/25343): Loss: 1.3616\n",
      "lossMSE: 2.1858043670654297 lossSSIM: 1.0360506772994995\n",
      "===> Epoch[1](50/25343): Loss: 1.3235\n",
      "lossMSE: 2.1437644958496094 lossSSIM: 1.034879207611084\n",
      "===> Epoch[1](100/25343): Loss: 1.3121\n",
      "lossMSE: 2.0976638793945312 lossSSIM: 1.0340828895568848\n",
      "===> Epoch[1](150/25343): Loss: 1.3000\n",
      "lossMSE: 2.1018261909484863 lossSSIM: 1.0319061279296875\n",
      "===> Epoch[1](200/25343): Loss: 1.2994\n",
      "lossMSE: 2.0222904682159424 lossSSIM: 1.0291587114334106\n",
      "===> Epoch[1](250/25343): Loss: 1.2774\n",
      "lossMSE: 2.0070016384124756 lossSSIM: 1.0280711650848389\n",
      "===> Epoch[1](300/25343): Loss: 1.2728\n",
      "lossMSE: 1.9654513597488403 lossSSIM: 1.0300029516220093\n",
      "===> Epoch[1](350/25343): Loss: 1.2639\n",
      "lossMSE: 1.9446958303451538 lossSSIM: 1.0274171829223633\n",
      "===> Epoch[1](400/25343): Loss: 1.2567\n",
      "lossMSE: 1.7757505178451538 lossSSIM: 1.0261132717132568\n",
      "===> Epoch[1](450/25343): Loss: 1.2135\n",
      "lossMSE: 1.8746812343597412 lossSSIM: 1.0288546085357666\n",
      "===> Epoch[1](500/25343): Loss: 1.2403\n",
      "lossMSE: 1.8633427619934082 lossSSIM: 1.026903510093689\n",
      "===> Epoch[1](550/25343): Loss: 1.2360\n",
      "lossMSE: 1.7845031023025513 lossSSIM: 1.0261729955673218\n",
      "===> Epoch[1](600/25343): Loss: 1.2158\n",
      "lossMSE: 1.7777868509292603 lossSSIM: 1.0250369310379028\n",
      "===> Epoch[1](650/25343): Loss: 1.2132\n",
      "lossMSE: 1.7344695329666138 lossSSIM: 1.022519588470459\n",
      "===> Epoch[1](700/25343): Loss: 1.2005\n",
      "lossMSE: 1.6798224449157715 lossSSIM: 1.022469401359558\n",
      "===> Epoch[1](750/25343): Loss: 1.1868\n",
      "lossMSE: 1.6869922876358032 lossSSIM: 1.0209256410598755\n",
      "===> Epoch[1](800/25343): Loss: 1.1874\n",
      "lossMSE: 1.6507718563079834 lossSSIM: 1.0208933353424072\n",
      "===> Epoch[1](850/25343): Loss: 1.1784\n",
      "lossMSE: 1.6282261610031128 lossSSIM: 1.0204373598098755\n",
      "===> Epoch[1](900/25343): Loss: 1.1724\n",
      "lossMSE: 1.6157786846160889 lossSSIM: 1.0192426443099976\n",
      "===> Epoch[1](950/25343): Loss: 1.1684\n",
      "lossMSE: 1.6655516624450684 lossSSIM: 1.01930570602417\n",
      "===> Epoch[1](1000/25343): Loss: 1.1809\n",
      "lossMSE: 1.619779348373413 lossSSIM: 1.0182253122329712\n",
      "===> Epoch[1](1050/25343): Loss: 1.1686\n",
      "lossMSE: 1.5785821676254272 lossSSIM: 1.0175480842590332\n",
      "===> Epoch[1](1100/25343): Loss: 1.1578\n",
      "lossMSE: 1.5468251705169678 lossSSIM: 1.0170462131500244\n",
      "===> Epoch[1](1150/25343): Loss: 1.1495\n",
      "lossMSE: 1.4863524436950684 lossSSIM: 1.016006588935852\n",
      "===> Epoch[1](1200/25343): Loss: 1.1336\n",
      "lossMSE: 1.5174973011016846 lossSSIM: 1.0156654119491577\n",
      "===> Epoch[1](1250/25343): Loss: 1.1411\n",
      "lossMSE: 1.4746400117874146 lossSSIM: 1.014661431312561\n",
      "===> Epoch[1](1300/25343): Loss: 1.1297\n",
      "lossMSE: 1.482857346534729 lossSSIM: 1.0142723321914673\n",
      "===> Epoch[1](1350/25343): Loss: 1.1314\n",
      "lossMSE: 1.4664924144744873 lossSSIM: 1.0140066146850586\n",
      "===> Epoch[1](1400/25343): Loss: 1.1271\n",
      "lossMSE: 1.4529083967208862 lossSSIM: 1.013063669204712\n",
      "===> Epoch[1](1450/25343): Loss: 1.1230\n",
      "lossMSE: 1.4845025539398193 lossSSIM: 1.0129297971725464\n",
      "===> Epoch[1](1500/25343): Loss: 1.1308\n",
      "lossMSE: 1.3369086980819702 lossSSIM: 1.0121588706970215\n",
      "===> Epoch[1](1550/25343): Loss: 1.0933\n",
      "lossMSE: 1.4044251441955566 lossSSIM: 1.0117043256759644\n",
      "===> Epoch[1](1600/25343): Loss: 1.1099\n",
      "lossMSE: 1.405211091041565 lossSSIM: 1.011838674545288\n",
      "===> Epoch[1](1650/25343): Loss: 1.1102\n",
      "lossMSE: 1.3744767904281616 lossSSIM: 1.0108232498168945\n",
      "===> Epoch[1](1700/25343): Loss: 1.1017\n",
      "lossMSE: 1.3446393013000488 lossSSIM: 1.0104397535324097\n",
      "===> Epoch[1](1750/25343): Loss: 1.0940\n",
      "lossMSE: 1.312569260597229 lossSSIM: 1.0103398561477661\n",
      "===> Epoch[1](1800/25343): Loss: 1.0859\n",
      "lossMSE: 1.3804736137390137 lossSSIM: 1.0104529857635498\n",
      "===> Epoch[1](1850/25343): Loss: 1.1030\n",
      "lossMSE: 1.3688298463821411 lossSSIM: 1.01009202003479\n",
      "===> Epoch[1](1900/25343): Loss: 1.0998\n",
      "lossMSE: 1.303547739982605 lossSSIM: 1.0138511657714844\n",
      "===> Epoch[1](1950/25343): Loss: 1.0863\n",
      "lossMSE: 1.276377558708191 lossSSIM: 1.0149191617965698\n",
      "===> Epoch[1](2000/25343): Loss: 1.0803\n",
      "lossMSE: 1.3385050296783447 lossSSIM: 1.0144262313842773\n",
      "===> Epoch[1](2050/25343): Loss: 1.0954\n",
      "lossMSE: 1.25860595703125 lossSSIM: 1.0142890214920044\n",
      "===> Epoch[1](2100/25343): Loss: 1.0754\n",
      "lossMSE: 1.30231773853302 lossSSIM: 1.0146749019622803\n",
      "===> Epoch[1](2150/25343): Loss: 1.0866\n",
      "lossMSE: 1.2953600883483887 lossSSIM: 1.0139553546905518\n",
      "===> Epoch[1](2200/25343): Loss: 1.0843\n",
      "lossMSE: 1.2628064155578613 lossSSIM: 1.0128788948059082\n",
      "===> Epoch[1](2250/25343): Loss: 1.0754\n",
      "lossMSE: 1.2179243564605713 lossSSIM: 1.0122129917144775\n",
      "===> Epoch[1](2300/25343): Loss: 1.0636\n",
      "lossMSE: 1.2058510780334473 lossSSIM: 1.011910080909729\n",
      "===> Epoch[1](2350/25343): Loss: 1.0604\n",
      "lossMSE: 1.2423030138015747 lossSSIM: 1.0121455192565918\n",
      "===> Epoch[1](2400/25343): Loss: 1.0697\n",
      "lossMSE: 1.1988437175750732 lossSSIM: 1.0117554664611816\n",
      "===> Epoch[1](2450/25343): Loss: 1.0585\n",
      "lossMSE: 1.193939208984375 lossSSIM: 1.0118900537490845\n",
      "===> Epoch[1](2500/25343): Loss: 1.0574\n",
      "lossMSE: 1.2126965522766113 lossSSIM: 1.0110876560211182\n",
      "===> Epoch[1](2550/25343): Loss: 1.0615\n",
      "lossMSE: 1.204535961151123 lossSSIM: 1.010859727859497\n",
      "===> Epoch[1](2600/25343): Loss: 1.0593\n",
      "lossMSE: 1.1873960494995117 lossSSIM: 1.0112028121948242\n",
      "===> Epoch[1](2650/25343): Loss: 1.0553\n",
      "lossMSE: 1.1695107221603394 lossSSIM: 1.010297417640686\n",
      "===> Epoch[1](2700/25343): Loss: 1.0501\n",
      "lossMSE: 1.1913280487060547 lossSSIM: 1.0105581283569336\n",
      "===> Epoch[1](2750/25343): Loss: 1.0558\n",
      "lossMSE: 1.1595988273620605 lossSSIM: 1.010222315788269\n",
      "===> Epoch[1](2800/25343): Loss: 1.0476\n",
      "lossMSE: 1.1721415519714355 lossSSIM: 1.010316014289856\n",
      "===> Epoch[1](2850/25343): Loss: 1.0508\n",
      "lossMSE: 1.1306166648864746 lossSSIM: 1.009803056716919\n",
      "===> Epoch[1](2900/25343): Loss: 1.0400\n",
      "lossMSE: 1.111863374710083 lossSSIM: 1.009509563446045\n",
      "===> Epoch[1](2950/25343): Loss: 1.0351\n",
      "lossMSE: 1.1552437543869019 lossSSIM: 1.0096478462219238\n",
      "===> Epoch[1](3000/25343): Loss: 1.0460\n",
      "lossMSE: 1.1368926763534546 lossSSIM: 1.0095207691192627\n",
      "===> Epoch[1](3050/25343): Loss: 1.0414\n",
      "lossMSE: 1.1274352073669434 lossSSIM: 1.0094270706176758\n",
      "===> Epoch[1](3100/25343): Loss: 1.0389\n",
      "lossMSE: 1.1032694578170776 lossSSIM: 1.0091913938522339\n",
      "===> Epoch[1](3150/25343): Loss: 1.0327\n",
      "lossMSE: 1.1628642082214355 lossSSIM: 1.009503960609436\n",
      "===> Epoch[1](3200/25343): Loss: 1.0478\n",
      "lossMSE: 1.1478791236877441 lossSSIM: 1.0095269680023193\n",
      "===> Epoch[1](3250/25343): Loss: 1.0441\n",
      "lossMSE: 1.1156057119369507 lossSSIM: 1.0088069438934326\n",
      "===> Epoch[1](3300/25343): Loss: 1.0355\n",
      "lossMSE: 1.14592707157135 lossSSIM: 1.0089302062988281\n",
      "===> Epoch[1](3350/25343): Loss: 1.0432\n",
      "lossMSE: 1.1123981475830078 lossSSIM: 1.0086917877197266\n",
      "===> Epoch[1](3400/25343): Loss: 1.0346\n",
      "lossMSE: 1.141771674156189 lossSSIM: 1.0065436363220215\n",
      "===> Epoch[1](3450/25343): Loss: 1.0404\n",
      "lossMSE: 1.1016545295715332 lossSSIM: 1.0062661170959473\n",
      "===> Epoch[1](3500/25343): Loss: 1.0301\n",
      "lossMSE: 1.1536706686019897 lossSSIM: 1.0063709020614624\n",
      "===> Epoch[1](3550/25343): Loss: 1.0432\n",
      "lossMSE: 1.1418355703353882 lossSSIM: 1.0063196420669556\n",
      "===> Epoch[1](3600/25343): Loss: 1.0402\n",
      "lossMSE: 1.079395055770874 lossSSIM: 1.005977988243103\n",
      "===> Epoch[1](3650/25343): Loss: 1.0243\n",
      "lossMSE: 1.136551856994629 lossSSIM: 1.0061180591583252\n",
      "===> Epoch[1](3700/25343): Loss: 1.0387\n",
      "lossMSE: 1.1310453414916992 lossSSIM: 1.0058377981185913\n",
      "===> Epoch[1](3750/25343): Loss: 1.0371\n",
      "lossMSE: 1.1472465991973877 lossSSIM: 1.005761981010437\n",
      "===> Epoch[1](3800/25343): Loss: 1.0411\n",
      "lossMSE: 1.1244006156921387 lossSSIM: 1.0053423643112183\n",
      "===> Epoch[1](3850/25343): Loss: 1.0351\n",
      "lossMSE: 1.119354009628296 lossSSIM: 1.0055713653564453\n",
      "===> Epoch[1](3900/25343): Loss: 1.0340\n",
      "lossMSE: 1.1042041778564453 lossSSIM: 1.0054125785827637\n",
      "===> Epoch[1](3950/25343): Loss: 1.0301\n",
      "lossMSE: 1.0926696062088013 lossSSIM: 1.0055859088897705\n",
      "===> Epoch[1](4000/25343): Loss: 1.0274\n",
      "lossMSE: 1.126105546951294 lossSSIM: 1.005143404006958\n",
      "===> Epoch[1](4050/25343): Loss: 1.0354\n",
      "lossMSE: 1.0893217325210571 lossSSIM: 1.005030870437622\n",
      "===> Epoch[1](4100/25343): Loss: 1.0261\n",
      "lossMSE: 1.0748182535171509 lossSSIM: 1.0050755739212036\n",
      "===> Epoch[1](4150/25343): Loss: 1.0225\n",
      "lossMSE: 1.1216237545013428 lossSSIM: 1.0051062107086182\n",
      "===> Epoch[1](4200/25343): Loss: 1.0342\n",
      "lossMSE: 1.1107900142669678 lossSSIM: 1.00499427318573\n",
      "===> Epoch[1](4250/25343): Loss: 1.0314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossMSE: 1.1003761291503906 lossSSIM: 1.0047268867492676\n",
      "===> Epoch[1](4300/25343): Loss: 1.0286\n",
      "lossMSE: 1.049142599105835 lossSSIM: 1.004579782485962\n",
      "===> Epoch[1](4350/25343): Loss: 1.0157\n",
      "lossMSE: 1.0749120712280273 lossSSIM: 1.004716157913208\n",
      "===> Epoch[1](4400/25343): Loss: 1.0223\n",
      "lossMSE: 1.0845999717712402 lossSSIM: 1.0047023296356201\n",
      "===> Epoch[1](4450/25343): Loss: 1.0247\n",
      "lossMSE: 1.1119210720062256 lossSSIM: 1.004279613494873\n",
      "===> Epoch[1](4500/25343): Loss: 1.0312\n",
      "lossMSE: 1.0710504055023193 lossSSIM: 1.0045636892318726\n",
      "===> Epoch[1](4550/25343): Loss: 1.0212\n",
      "lossMSE: 1.100809097290039 lossSSIM: 1.0044628381729126\n",
      "===> Epoch[1](4600/25343): Loss: 1.0285\n",
      "lossMSE: 1.05734384059906 lossSSIM: 1.0042668581008911\n",
      "===> Epoch[1](4650/25343): Loss: 1.0175\n",
      "lossMSE: 1.1011220216751099 lossSSIM: 1.0044922828674316\n",
      "===> Epoch[1](4700/25343): Loss: 1.0286\n",
      "lossMSE: 1.0729526281356812 lossSSIM: 1.0040820837020874\n",
      "===> Epoch[1](4750/25343): Loss: 1.0213\n",
      "lossMSE: 1.1010494232177734 lossSSIM: 1.00400972366333\n",
      "===> Epoch[1](4800/25343): Loss: 1.0283\n",
      "lossMSE: 1.096006155014038 lossSSIM: 1.0040603876113892\n",
      "===> Epoch[1](4850/25343): Loss: 1.0270\n",
      "lossMSE: 1.073204517364502 lossSSIM: 1.0041906833648682\n",
      "===> Epoch[1](4900/25343): Loss: 1.0214\n",
      "lossMSE: 1.085283637046814 lossSSIM: 1.0039633512496948\n",
      "===> Epoch[1](4950/25343): Loss: 1.0243\n",
      "lossMSE: 1.0956770181655884 lossSSIM: 1.0040647983551025\n",
      "===> Epoch[1](5000/25343): Loss: 1.0270\n",
      "lossMSE: 1.041346549987793 lossSSIM: 1.0041650533676147\n",
      "===> Epoch[1](5050/25343): Loss: 1.0135\n",
      "lossMSE: 1.0306189060211182 lossSSIM: 1.0036580562591553\n",
      "===> Epoch[1](5100/25343): Loss: 1.0104\n",
      "lossMSE: 1.0808393955230713 lossSSIM: 1.0040485858917236\n",
      "===> Epoch[1](5150/25343): Loss: 1.0232\n",
      "lossMSE: 1.1000617742538452 lossSSIM: 1.0038059949874878\n",
      "===> Epoch[1](5200/25343): Loss: 1.0279\n",
      "lossMSE: 1.0307403802871704 lossSSIM: 1.0035513639450073\n",
      "===> Epoch[1](5250/25343): Loss: 1.0103\n",
      "lossMSE: 1.0629096031188965 lossSSIM: 1.0036934614181519\n",
      "===> Epoch[1](5300/25343): Loss: 1.0185\n",
      "lossMSE: 1.03687584400177 lossSSIM: 1.0035433769226074\n",
      "===> Epoch[1](5350/25343): Loss: 1.0119\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10 + 1):\n",
    "    train(epoch)\n",
    "#     test()\n",
    "#     checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "def test():\n",
    "    avg_psnr = 0\n",
    "    with torch.no_grad():\n",
    "        for iteration, batch in enumerate(dataloader):\n",
    "            input, target = batch['input'].to(device), batch['output'].to(device)\n",
    "                \n",
    "            prediction = model(input)\n",
    "\n",
    "            target = target.float()\n",
    "\n",
    "            outdataloader = {'input':prediction,'output':target}\n",
    "            \n",
    "            print(outdataloader['input'].size(), \n",
    "                      outdataloader['output'].size())\n",
    "\n",
    "            plt.figure()\n",
    "            input_batch, label_batch = outdataloader['input'], outdataloader['output']\n",
    "            batch_size = 32\n",
    "            im_size = input_batch.size(2)\n",
    "            label_batch=label_batch.reshape([batch_size,1,im_size,im_size])\n",
    "            print(label_batch.size())\n",
    "            for img in input_batch:\n",
    "                for t, m, s in zip(img, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]):\n",
    "                    t.mul_(s).add_(m)\n",
    "                            \n",
    "            for img in label_batch:\n",
    "                for t, m, s in zip(img, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]):\n",
    "                    t.mul_(s).add_(m)                           \n",
    "\n",
    "            grid = utils.make_grid(input_batch).cpu()\n",
    "            plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "            plt.figure()\n",
    "\n",
    "            grid = utils.make_grid(label_batch).cpu()\n",
    "            plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "            plt.axis('off')\n",
    "            plt.ioff()\n",
    "            plt.show()\n",
    "            \n",
    "            targetf = target[:, None]\n",
    "            \n",
    "            lossMSE = criterionMSE(prediction, targetf)      \n",
    "            lossSSIM = -ssim(prediction, targetf)\n",
    "        \n",
    "            p = 0.25\n",
    "            loss = p*lossMSE + (1-p)*lossSSIM\n",
    "            combineLoss = p*lossMSE.item() + (1-p)*lossSSIM.item()\n",
    "#             mse = criterion(prediction, target.float())\n",
    "\n",
    "            psnr = 10 * torch.log10(1 / loss)\n",
    "            avg_psnr += psnr\n",
    "            if iteration == 16:\n",
    "                break\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restart\n",
    "for epoch in range(1, 5 + 1):\n",
    "    train(epoch)\n",
    "#     test()\n",
    "#     checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
