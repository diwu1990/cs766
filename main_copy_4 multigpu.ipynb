{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import data as dt\n",
    "import model_4_o as md\n",
    "import copy\n",
    "from pytorch_ssim import ssim\n",
    "from torch.utils.data import DataLoader\n",
    "# e/d + i\n",
    "# best mode so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print gpu\n",
    "torch.cuda.set_device(1)\n",
    "currentDevice = torch.cuda.current_device()\n",
    "print(\"Current GPU: \" + str(currentDevice))\n",
    "print(str(torch.cuda.device_count()))\n",
    "print(str(torch.cuda.get_device_capability(currentDevice)))\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = 1\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate csv file, run only for the first time\n",
    "# dt.generate_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilePath = dt.get_csv_path()\n",
    "transformed_dataset = dt.HE_SHG_Dataset(csv_file=csvFilePath,\n",
    "                                               transform=dt.Compose([                                              \n",
    "                                               dt.Rescale(96),                                     \n",
    "                                               dt.Normalize(),\n",
    "                                               dt.ToTensor()\n",
    "                                           ]))\n",
    "# TODO: change the normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize 32->16\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=1200,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: insert back mean and variance to plot the image appropriately\n",
    "dt.show_patch(dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (block0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (info1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (info2): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (side3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (side4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (side5): Sequential(\n",
       "    (0): ConvTranspose2d(256, 128, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block6): Sequential(\n",
       "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "    (3): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (side6): Sequential(\n",
       "    (0): ConvTranspose2d(128, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block7): Sequential(\n",
       "    (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block8): Sequential(\n",
       "    (0): Conv2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (block9): Sequential(\n",
       "    (0): PixelShuffle(upscale_factor=2)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd();\n",
    "path = os.path.join(cwd, 'Saved model', 'encoderresinfo.pth')\n",
    "model = md.Net()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionMSE = nn.MSELoss()\n",
    "criterionMSE = criterionMSE.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, p, windowsize):\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(dataloader):\n",
    "        input, target = batch['input'].to(device), batch['output'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        targetf = target.float()\n",
    "        targetf = targetf[:, None]\n",
    "        \n",
    "        lossMSE = criterionMSE(output, targetf)      \n",
    "        lossSSIM = 1-ssim(output, targetf, window_size=windowsize)\n",
    "        \n",
    "        # 0.75->0.4 after 3 epochs\n",
    "        loss = p*lossMSE + (1-p)*lossSSIM\n",
    "        combineLoss = p*lossMSE.item() + (1-p)*lossSSIM.item()\n",
    "        \n",
    "        epoch_loss = epoch_loss + combineLoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if iteration%50 == 0:\n",
    "            print(\"lossMSE: \" + str(lossMSE.item()) +\n",
    "                  \" \" + \"lossSSIM: \" + str(lossSSIM.item()))\n",
    "            print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(dataloader), loss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(dataloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     avg_psnr = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in testing_data_loader:\n",
    "#             input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "#             prediction = model(input)\n",
    "#             mse = criterion(prediction, target)\n",
    "#             psnr = 10 * log10(1 / mse.item())\n",
    "#             avg_psnr += psnr\n",
    "#     print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkpoint(epoch):\n",
    "#     model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
    "#     torch.save(model, model_out_path)\n",
    "#     print(\"Checkpoint saved to {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 10 + 1):\n",
    "    train(epoch)\n",
    "#     test()\n",
    "#     checkpoint(epoch)\n",
    "#     wanna loss < 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "def test():\n",
    "    avg_psnr = 0\n",
    "    with torch.no_grad():\n",
    "        for iteration, batch in enumerate(dataloader):\n",
    "            input, target = batch['input'].to(device), batch['output'].to(device)\n",
    "                \n",
    "            prediction = model(input)\n",
    "\n",
    "            target = target.float()\n",
    "\n",
    "            outdataloader = {'input':prediction,'output':target}\n",
    "            \n",
    "            print(outdataloader['input'].size(), \n",
    "                      outdataloader['output'].size())\n",
    "\n",
    "            plt.figure()\n",
    "            input_batch, label_batch = outdataloader['input'], outdataloader['output']\n",
    "            batch_size = 32\n",
    "            im_size = input_batch.size(2)\n",
    "            label_batch=label_batch.reshape([batch_size,1,im_size,im_size])\n",
    "            print(label_batch.size())\n",
    "#             for img in input_batch:\n",
    "#                 for t, m, s in zip(img, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]):\n",
    "#                     t.mul_(s).add_(m)\n",
    "                            \n",
    "#             for img in label_batch:\n",
    "#                 for t, m, s in zip(img, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]):\n",
    "#                     t.mul_(s).add_(m)                           \n",
    "            grid = utils.make_grid(input).cpu()\n",
    "            plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "            plt.figure()\n",
    "    \n",
    "            grid = utils.make_grid(input_batch).cpu()\n",
    "            plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "            plt.figure()\n",
    "\n",
    "            grid = utils.make_grid(label_batch).cpu()\n",
    "            plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "            plt.axis('off')\n",
    "            plt.ioff()\n",
    "            plt.show()\n",
    "            \n",
    "            targetf = target[:, None]\n",
    "            \n",
    "            lossMSE = criterionMSE(prediction, targetf)      \n",
    "            lossSSIM = -ssim(prediction, targetf)\n",
    "        \n",
    "            p = 0.25\n",
    "            loss = p*lossMSE + (1-p)*lossSSIM\n",
    "            combineLoss = p*lossMSE.item() + (1-p)*lossSSIM.item()\n",
    "#             mse = criterion(prediction, target.float())\n",
    "\n",
    "            psnr = 10 * torch.log10(1 / loss)\n",
    "            avg_psnr += psnr\n",
    "            if iteration == 16:\n",
    "                break\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = 0.0001\n",
    "p = 0.5\n",
    "windowsize = 3\n",
    "for epoch in range(1, 18 + 1):\n",
    "    if epoch%2 == 0:\n",
    "        windowsize = windowsize+1\n",
    "        p = p*0.8\n",
    "        l = l*0.2\n",
    "        if windowsize == 0:\n",
    "            windowsze = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "        \n",
    "    train(epoch, p, windowsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd();\n",
    "path = os.path.join(cwd, 'Saved model', 'encoderresinfo.pth')\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.0001\n",
    "p = 0\n",
    "windowsize = 4\n",
    "for epoch in range(1, 20 + 1):\n",
    "    if epoch%5 == 0:\n",
    "        windowsize = windowsize+1\n",
    "        p = p*1\n",
    "        l = l*0.2\n",
    "        if windowsize == 0:\n",
    "            windowsze = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "        \n",
    "    train(epoch, p, windowsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.00001\n",
    "p = 0\n",
    "windowsize = 10\n",
    "for epoch in range(1, 20 + 1):\n",
    "    if epoch%5 == 0:\n",
    "        windowsize = windowsize+1\n",
    "        p = p*1\n",
    "        l = l*0.2\n",
    "        if windowsize >= 20:\n",
    "            windowsze = 20\n",
    "    optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "        \n",
    "    train(epoch, p, windowsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (block0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (info1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (info2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (side3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (side4): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block5): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "      (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (side5): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block6): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "      (3): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (side6): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block7): Sequential(\n",
       "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block8): Sequential(\n",
       "      (0): Conv2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (block9): Sequential(\n",
       "      (0): PixelShuffle(upscale_factor=2)\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_ids = [1, 2, 3, 4, 5, 6]\n",
    "torch.cuda.set_device(gpu_ids[0])\n",
    "model = torch.nn.DataParallel(model, device_ids=gpu_ids)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossMSE: 0.0061826989986002445 lossSSIM: 0.26286572217941284\n",
      "===> Epoch[1](0/676): Loss: 0.2629\n",
      "lossMSE: 0.007225800771266222 lossSSIM: 0.26099473237991333\n",
      "===> Epoch[1](50/676): Loss: 0.2610\n",
      "lossMSE: 0.006101866252720356 lossSSIM: 0.2660636901855469\n",
      "===> Epoch[1](100/676): Loss: 0.2661\n",
      "lossMSE: 0.006052036304026842 lossSSIM: 0.2484944462776184\n",
      "===> Epoch[1](150/676): Loss: 0.2485\n",
      "lossMSE: 0.006251385901123285 lossSSIM: 0.2548221945762634\n",
      "===> Epoch[1](200/676): Loss: 0.2548\n",
      "lossMSE: 0.007263422477990389 lossSSIM: 0.2613692879676819\n",
      "===> Epoch[1](250/676): Loss: 0.2614\n",
      "lossMSE: 0.0062272027134895325 lossSSIM: 0.2564438581466675\n",
      "===> Epoch[1](300/676): Loss: 0.2564\n",
      "lossMSE: 0.006103506311774254 lossSSIM: 0.2573243975639343\n",
      "===> Epoch[1](350/676): Loss: 0.2573\n",
      "lossMSE: 0.0060762688517570496 lossSSIM: 0.2600712180137634\n",
      "===> Epoch[1](400/676): Loss: 0.2601\n",
      "lossMSE: 0.006617461796849966 lossSSIM: 0.2579900026321411\n",
      "===> Epoch[1](450/676): Loss: 0.2580\n",
      "lossMSE: 0.00664266524836421 lossSSIM: 0.2637396454811096\n",
      "===> Epoch[1](500/676): Loss: 0.2637\n",
      "lossMSE: 0.007218419574201107 lossSSIM: 0.2674495577812195\n",
      "===> Epoch[1](550/676): Loss: 0.2674\n",
      "lossMSE: 0.006718538235872984 lossSSIM: 0.2580419182777405\n",
      "===> Epoch[1](600/676): Loss: 0.2580\n"
     ]
    }
   ],
   "source": [
    "l = 0.0001\n",
    "p = 0\n",
    "windowsize = 10\n",
    "for epoch in range(1, 20 + 1):\n",
    "    if epoch%5 == 0:\n",
    "        windowsize = windowsize+1\n",
    "        p = p*1\n",
    "        l = l*1\n",
    "        if windowsize >= 20:\n",
    "            windowsze = 20\n",
    "    optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "        \n",
    "    train(epoch, p, windowsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
