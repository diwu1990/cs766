{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datanew as dt\n",
    "import model_4_op as md\n",
    "import copy\n",
    "from pytorch_ssim import ssim\n",
    "from torch.utils.data import DataLoader\n",
    "# e/d + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITAN V\n",
      "0\n",
      "Current GPU: 0\n",
      "8\n",
      "(7, 0)\n",
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "# print gpu\n",
    "torch.cuda.set_device(0)\n",
    "currentDevice = torch.cuda.current_device()\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(currentDevice)\n",
    "print(\"Current GPU: \" + str(currentDevice))\n",
    "print(str(torch.cuda.device_count()))\n",
    "print(str(torch.cuda.get_device_capability(currentDevice)))\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = 1\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate csv file, run only for the first time\n",
    "# dt.generate_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilePath = dt.get_csv_path()\n",
    "transformed_dataset = dt.HE_SHG_Dataset(csv_file=csvFilePath,\n",
    "                                               transform=dt.Compose([                                              \n",
    "                                               dt.Rescale(96),                                     \n",
    "                                               dt.Normalize(),\n",
    "                                               dt.ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "# for testing\n",
    "transformed_dataset_raw = dt.HE_SHG_Dataset(csv_file=csvFilePath,\n",
    "                                               transform=dt.Compose([                                              \n",
    "                                               dt.Rescale(96),                                     \n",
    "                                               dt.ToTensor()\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batchsize 32->16\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=32,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "# for testing\n",
    "dataloader_raw = DataLoader(transformed_dataset_raw, batch_size=32,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: insert back mean and variance to plot the image appropriately\n",
    "dt.show_patch(dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt.show_patch(dataloader_raw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_test = dt.get_one_batch(dataloader_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample, meanHE, stdHE, meanSHG, stdSHG = dt.normalizebatch(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.show_one_batch(sample, meanHE, stdHE, meanSHG, stdSHG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n"
     ]
    }
   ],
   "source": [
    "print('===> Building model')\n",
    "model = md.Net().to(device)\n",
    "criterionMSE = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, p, windowsize):\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(dataloader):\n",
    "        input, target = batch['input'].to(device), batch['output'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        targetf = target.float()\n",
    "        targetf = targetf[:, None]\n",
    "        \n",
    "        lossMSE = criterionMSE(output, targetf)      \n",
    "        lossSSIM = 1-ssim(output, targetf, window_size=windowsize)\n",
    "        \n",
    "        # 0.75->0.4 after 3 epochs\n",
    "        loss = p*lossMSE + (1-p)*lossSSIM\n",
    "        combineLoss = p*lossMSE.item() + (1-p)*lossSSIM.item()\n",
    "        \n",
    "        epoch_loss = epoch_loss + combineLoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if iteration%50 == 0:\n",
    "            print(\"lossMSE: \" + str(lossMSE.item()) +\n",
    "                  \" \" + \"lossSSIM: \" + str(lossSSIM.item()))\n",
    "            print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(dataloader), loss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(dataloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     avg_psnr = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in testing_data_loader:\n",
    "#             input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "#             prediction = model(input)\n",
    "#             mse = criterion(prediction, target)\n",
    "#             psnr = 10 * log10(1 / mse.item())\n",
    "#             avg_psnr += psnr\n",
    "#     print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def checkpoint(epoch):\n",
    "#     model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
    "#     torch.save(model, model_out_path)\n",
    "#     print(\"Checkpoint saved to {}\".format(model_out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "def test():\n",
    "    avg_psnr = 0\n",
    "    with torch.no_grad():\n",
    "        for iteration, batch in enumerate(dataloader_raw):\n",
    "            batch, meanHE, stdHE, meanSHG, stdSHG = dt.normalizebatch(batch)\n",
    "            input, target = batch['input'].to(device), batch['output'].to(device)\n",
    "                \n",
    "            prediction = model(input)\n",
    "\n",
    "            target = target.float()\n",
    "\n",
    "            outdataloader = {'input':prediction,'output':target}\n",
    "            \n",
    "            print(outdataloader['input'].size(), \n",
    "                      outdataloader['output'].size())\n",
    "\n",
    "            plt.figure()\n",
    "            input_batch, label_batch = outdataloader['input'], outdataloader['output']\n",
    "            batch_size = 32\n",
    "            im_size = input_batch.size(2)\n",
    "            label_batch=label_batch.reshape([batch_size,1,im_size,im_size])\n",
    "            print(label_batch.size())\n",
    "#             for img in input_batch:\n",
    "#                 for t, m, s in zip(img, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]):\n",
    "#                     t.mul_(s).add_(m)\n",
    "                            \n",
    "#             for img in label_batch:\n",
    "#                 for t, m, s in zip(img, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]):\n",
    "#                     t.mul_(s).add_(m)                           \n",
    "\n",
    "            grid = utils.make_grid(input_batch).cpu()\n",
    "            plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "            plt.figure()\n",
    "\n",
    "            grid = utils.make_grid(label_batch).cpu()\n",
    "            plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "            plt.axis('off')\n",
    "            plt.ioff()\n",
    "            plt.show()\n",
    "            \n",
    "            targetf = target[:, None]\n",
    "            \n",
    "            lossMSE = criterionMSE(prediction, targetf)      \n",
    "            lossSSIM = -ssim(prediction, targetf)\n",
    "        \n",
    "            p = 0.25\n",
    "            loss = p*lossMSE + (1-p)*lossSSIM\n",
    "            combineLoss = p*lossMSE.item() + (1-p)*lossSSIM.item()\n",
    "#             mse = criterion(prediction, target.float())\n",
    "\n",
    "            psnr = 10 * torch.log10(1 / loss)\n",
    "            avg_psnr += psnr\n",
    "            if iteration == 16:\n",
    "                break\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossMSE: 0.309888631105423 lossSSIM: 0.9932149052619934\n",
      "===> Epoch[1](0/25343): Loss: 0.4807\n",
      "lossMSE: 0.21992065012454987 lossSSIM: 0.9389750361442566\n",
      "===> Epoch[1](50/25343): Loss: 0.3997\n",
      "lossMSE: 0.22309663891792297 lossSSIM: 0.9399890899658203\n",
      "===> Epoch[1](100/25343): Loss: 0.4023\n",
      "lossMSE: 0.21575605869293213 lossSSIM: 0.9338243007659912\n",
      "===> Epoch[1](150/25343): Loss: 0.3953\n",
      "lossMSE: 0.22703726589679718 lossSSIM: 0.9500573873519897\n",
      "===> Epoch[1](200/25343): Loss: 0.4078\n",
      "lossMSE: 0.2206663340330124 lossSSIM: 0.9433647990226746\n",
      "===> Epoch[1](250/25343): Loss: 0.4013\n",
      "lossMSE: 0.21714414656162262 lossSSIM: 0.9406930208206177\n",
      "===> Epoch[1](300/25343): Loss: 0.3980\n",
      "lossMSE: 0.2099798023700714 lossSSIM: 0.9368406534194946\n",
      "===> Epoch[1](350/25343): Loss: 0.3917\n",
      "lossMSE: 0.2133486568927765 lossSSIM: 0.9387649297714233\n",
      "===> Epoch[1](400/25343): Loss: 0.3947\n",
      "lossMSE: 0.21111668646335602 lossSSIM: 0.9344047904014587\n",
      "===> Epoch[1](450/25343): Loss: 0.3919\n",
      "lossMSE: 0.20733529329299927 lossSSIM: 0.9349241256713867\n",
      "===> Epoch[1](500/25343): Loss: 0.3892\n",
      "lossMSE: 0.2091163545846939 lossSSIM: 0.9365062713623047\n",
      "===> Epoch[1](550/25343): Loss: 0.3910\n",
      "lossMSE: 0.20744845271110535 lossSSIM: 0.929699182510376\n",
      "===> Epoch[1](600/25343): Loss: 0.3880\n",
      "lossMSE: 0.2148715853691101 lossSSIM: 0.9476481080055237\n",
      "===> Epoch[1](650/25343): Loss: 0.3981\n",
      "lossMSE: 0.2058226466178894 lossSSIM: 0.9350354671478271\n",
      "===> Epoch[1](700/25343): Loss: 0.3881\n",
      "lossMSE: 0.20949971675872803 lossSSIM: 0.9499489068984985\n",
      "===> Epoch[1](750/25343): Loss: 0.3946\n",
      "lossMSE: 0.21786445379257202 lossSSIM: 0.957337498664856\n",
      "===> Epoch[1](800/25343): Loss: 0.4027\n",
      "lossMSE: 0.20327356457710266 lossSSIM: 0.9358028173446655\n",
      "===> Epoch[1](850/25343): Loss: 0.3864\n",
      "lossMSE: 0.19888299703598022 lossSSIM: 0.9361307621002197\n",
      "===> Epoch[1](900/25343): Loss: 0.3832\n",
      "lossMSE: 0.20628520846366882 lossSSIM: 0.9404279589653015\n",
      "===> Epoch[1](950/25343): Loss: 0.3898\n",
      "lossMSE: 0.20515762269496918 lossSSIM: 0.9411792755126953\n",
      "===> Epoch[1](1000/25343): Loss: 0.3892\n",
      "lossMSE: 0.19988936185836792 lossSSIM: 0.9395073652267456\n",
      "===> Epoch[1](1050/25343): Loss: 0.3848\n",
      "lossMSE: 0.20164988934993744 lossSSIM: 0.9390994310379028\n",
      "===> Epoch[1](1100/25343): Loss: 0.3860\n",
      "lossMSE: 0.1982429027557373 lossSSIM: 0.9330207705497742\n",
      "===> Epoch[1](1150/25343): Loss: 0.3819\n",
      "lossMSE: 0.19601091742515564 lossSSIM: 0.9294265508651733\n",
      "===> Epoch[1](1200/25343): Loss: 0.3794\n",
      "lossMSE: 0.20482562482357025 lossSSIM: 0.946321427822113\n",
      "===> Epoch[1](1250/25343): Loss: 0.3902\n",
      "lossMSE: 0.19377228617668152 lossSSIM: 0.9311563372612\n",
      "===> Epoch[1](1300/25343): Loss: 0.3781\n",
      "lossMSE: 0.1956142783164978 lossSSIM: 0.9380269646644592\n",
      "===> Epoch[1](1350/25343): Loss: 0.3812\n",
      "lossMSE: 0.19213064014911652 lossSSIM: 0.9268316030502319\n",
      "===> Epoch[1](1400/25343): Loss: 0.3758\n",
      "lossMSE: 0.20336662232875824 lossSSIM: 0.947834312915802\n",
      "===> Epoch[1](1450/25343): Loss: 0.3895\n",
      "lossMSE: 0.19529663026332855 lossSSIM: 0.9382742643356323\n",
      "===> Epoch[1](1500/25343): Loss: 0.3810\n",
      "lossMSE: 0.18503957986831665 lossSSIM: 0.9281648397445679\n",
      "===> Epoch[1](1550/25343): Loss: 0.3708\n",
      "lossMSE: 0.1888355165719986 lossSSIM: 0.9411882758140564\n",
      "===> Epoch[1](1600/25343): Loss: 0.3769\n",
      "lossMSE: 0.18953752517700195 lossSSIM: 0.9356725811958313\n",
      "===> Epoch[1](1650/25343): Loss: 0.3761\n",
      "lossMSE: 0.19446179270744324 lossSSIM: 0.9420315027236938\n",
      "===> Epoch[1](1700/25343): Loss: 0.3814\n",
      "lossMSE: 0.18183231353759766 lossSSIM: 0.9294323921203613\n",
      "===> Epoch[1](1750/25343): Loss: 0.3687\n",
      "lossMSE: 0.18640770018100739 lossSSIM: 0.9419069290161133\n",
      "===> Epoch[1](1800/25343): Loss: 0.3753\n",
      "lossMSE: 0.1971072405576706 lossSSIM: 0.9575960040092468\n",
      "===> Epoch[1](1850/25343): Loss: 0.3872\n"
     ]
    }
   ],
   "source": [
    "l = 0.001\n",
    "p = 0.75\n",
    "windowsize = 4\n",
    "for epoch in range(1, 20 + 1):\n",
    "    if epoch%5 == 0:\n",
    "        windowsize = windowsize+1\n",
    "        p = p*0.5\n",
    "        l = l*0.8\n",
    "        if windowsize == 0:\n",
    "            windowsze = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "        \n",
    "    train(epoch, p, windowsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd();\n",
    "path = os.path.join(cwd, 'Saved model', 'encoderresinfo.pth')\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.0001\n",
    "p = 0\n",
    "windowsize = 4\n",
    "for epoch in range(1, 20 + 1):\n",
    "    if epoch%5 == 0:\n",
    "        windowsize = windowsize+1\n",
    "        p = p*1\n",
    "        l = l*0.2\n",
    "        if windowsize == 0:\n",
    "            windowsze = 1\n",
    "    optimizer = optim.Adam(model.parameters(), lr=l)\n",
    "        \n",
    "    train(epoch, p, windowsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
